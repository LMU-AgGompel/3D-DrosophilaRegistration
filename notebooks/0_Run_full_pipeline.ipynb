{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a07cb409-d49a-4524-b01d-9c0f365c4cc2",
   "metadata": {},
   "source": [
    "# Registration of confocal images of Drosophila abdomens \n",
    "\n",
    "This notebook runs the pipeline to register the confocal images of fly abdomens.\n",
    "The analysis is divided in few steps.\n",
    "Each step uses functions saved in files in the src folder and its subfolders. \n",
    "\n",
    "The results of each step of the analysis are saved in a series of numbered subfolders in the data folder.\n",
    "\n",
    "The input raw data should be saved in the 01_raw subfolder as separate .tif files for each channel with a prefix that identifies the channel (like C1-filename.tif).  It should also contain an excel file with the columns \"image file name\", \"type\" and \"quality\". These columns contain the name of each image stack, a label identifying to which group or genotype the image stack belongs to, and a label characterizing the quality of the raw data for filtering the results at a later point in the analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21102829-4228-4f22-b824-ac2a914c1066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packaging and add the src folder to the path.\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "root_dir = os.path.join(os.getcwd(), '..')\n",
    "sys.path.append(root_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef71114d",
   "metadata": {},
   "source": [
    "## 1. Automated segmentation of the abdomens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f769d103-75a1-46c2-a1f4-063949295d83",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "Preprocessing of raw images in progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 3/3 [00:06<00:00,  2.06s/it]\n"
     ]
    }
   ],
   "source": [
    "# Importing the preprocessing function from the preprocess.py file:\n",
    "\n",
    "from src.preprocess import preprocess_and_segment_images\n",
    "\n",
    "raw_data_folder = \"../test_dataset/01_raw\"\n",
    "destination_folder = \"../test_dataset/02_preprocessed\"\n",
    "\n",
    "#downscaling of confocal stacks along z,x,y to make the resolution isotropic:\n",
    "downscaling = (1, 2.5, 2.5) \n",
    "\n",
    "# bit depth of raw images (depending on the detector settings may be 8, 12 or 16)\n",
    "bit_depth = 12\n",
    "\n",
    "# name of the excel file containing the list of images to be used in the analysis. \n",
    "db_name = 'DatasetInformation.xlsx'\n",
    "\n",
    "# default values of the parameters used for the segmentation:\n",
    "segm_pars={'threshold': 1.05, 'max_iter': 200,'fraction_range': [0.04, 0.05], \n",
    "           'padding': 20, 'closing_r': 4, 'dilation_r': 3, 'mesh_radius': 10}\n",
    "\n",
    "preprocess_and_segment_images(raw_data_folder, destination_folder, downscaling, bit_depth, \n",
    "                              only_on_new_files = False, segmentation_parameters=segm_pars, \n",
    "                              database_filename = db_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5d8776",
   "metadata": {},
   "source": [
    "## 2. Manual registration of the segmented 3D images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cde195c7-32dd-4180-b4f3-32440c376dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registration of 3D stacks in progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 3/3 [09:11<00:00, 183.78s/it]\n"
     ]
    }
   ],
   "source": [
    "# Importing the registration function from the registration.py file:\n",
    "\n",
    "from src.registration import run_manual_registration\n",
    "\n",
    "\"\"\"\n",
    "# USER INPUT IS REQUIRED, two windows with a 3D rendering of the detected object\n",
    "will pop-up for each image in the dataset. \n",
    "The first window shows the source object to register, the second one shows the reference target object.\n",
    "\n",
    "For each couple of images:\n",
    "1)  Please pick at least three correspondences using [shift + left click]\n",
    "    Press [shift + right click] to undo point picking)\n",
    "2)  After picking points, press 'Q' to close the window\n",
    "3)  Repeat points 1 and 2 for the reference image in the second window.\n",
    "4)  The next window will show the result of the registration, press 'Q' to close the window.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "read_folder = \"../test_dataset/02_preprocessed\"\n",
    "destination_folder = \"../test_dataset/03_registered\"\n",
    "\n",
    "reference_fly_filename = \"../test_dataset/References_and_masks/C1_Reference_iso.tiff\"\n",
    "\n",
    "df_name = \"DatasetInformation.xlsx\"\n",
    "\n",
    "preprocessed_df = pd.read_excel(os.path.join(read_folder,df_name))\n",
    "run_manual_registration(preprocessed_df, read_folder, reference_fly_filename, \n",
    "                        destination_folder, only_on_new_files = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b256590d",
   "metadata": {},
   "source": [
    "## 3. Automated 2D projection of registered 3D images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79ccfee3-8e27-4a57-871e-d820aa423d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Projection of registered 3D stacks to 2D images in progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 3/3 [00:06<00:00,  2.17s/it]\n"
     ]
    }
   ],
   "source": [
    "from src.projection import run_2D_projection\n",
    "\n",
    "read_folder = \"../test_dataset/03_registered\"\n",
    "destination_folder = \"../test_dataset/04_projected\"\n",
    "landmark_folder = \"../test_dataset/05_landmarks/data\"\n",
    "abdomen_mask_file = \"../test_dataset/References_and_masks/Reference_mask_iso_thick.tiff\"\n",
    "abdomen_shape_reference_file = \"../test_dataset/References_and_masks/Reference_mask_iso.tiff\"\n",
    "\n",
    "df_name = \"DatasetInformation.xlsx\"\n",
    "df = pd.read_excel(os.path.join(read_folder,df_name))\n",
    "\n",
    "# default values used by the projection algorithm:\n",
    "params = {'min_y':0, 'meridian_plane_x':62,'spline_smoothing':5, 'projection_radius':5}\n",
    "\n",
    "run_2D_projection(df, read_folder, destination_folder, landmark_folder, abdomen_mask_file,\n",
    "                  abdomen_shape_reference_file, crop_x=150, crop_y = 150, only_on_new_files = False, \n",
    "                  projection_parameters = params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5495686",
   "metadata": {},
   "source": [
    "##  4. Annotation and warping of the 2D projected images\n",
    "\n",
    "After the projection from 3D to 2D, images are already roughly aligned. However, the alignment up to this point was only performed by applying a global rescaling and rigid rotations/translations of the original stacks.\n",
    "\n",
    "To fine tune the registration we need to perform an elastic transformation of the final images. The following cell of the notebook starts a graphical interface that allows to manually annotate landmarks on the projected images and then register them on a reference.\n",
    "\n",
    "in the interface, open the annotation project, add the new images found in the folder 05_landmarks/data to the project. Annotate the new images and run the registration, save the results in the folder 06_warped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b442c82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.image_registration_gui import gui\n",
    "\n",
    "gui.start(main_window_size = (1000, 1000), graph_canvas_width = 600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50b2e2f",
   "metadata": {},
   "source": [
    "## 5. Final touch: smoothing and masking\n",
    "\n",
    "The final step applies a binary mask and a gaussian smoothing filter to the images. The width of the gaussian smoothing can be set to different values along the x and y axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cebb4d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/ceolin/Data/Lab Gompel/Projects/Fly_Abdomens/abdomens_registration/notebooks/../src/masking_smoothing.py:81: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  norm_mask_tmp = (1 / aux_convolution(\n",
      "/media/ceolin/Data/Lab Gompel/Projects/Fly_Abdomens/abdomens_registration/notebooks/../src/masking_smoothing.py:81: RuntimeWarning: invalid value encountered in multiply\n",
      "  norm_mask_tmp = (1 / aux_convolution(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smoothing and masking of the registered images in progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 9/9 [00:00<00:00, 223.11it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from src.masking_smoothing import run_smoothing_masking\n",
    "\n",
    "destination_folder = \"../test_dataset/07_masked_and_smooth\"\n",
    "read_folder = \"../test_dataset/06_warped\"\n",
    "mask = '../test_dataset/References_and_masks/Mask2d.tif'\n",
    "database_registered_images = \"../test_dataset/06_warped/dataframe_info.csv\"\n",
    "database_info = \"../test_dataset/04_projected/DatasetInformation.xlsx\"\n",
    "\n",
    "df_images = pd.read_csv(database_registered_images)\n",
    "df_info = pd.read_excel(database_info)\n",
    "\n",
    "smooth_x = 2\n",
    "smooth_y = 1\n",
    "\n",
    "run_smoothing_masking(\n",
    "        read_folder, destination_folder, df_images, df_info,\n",
    "        mask, smooth_x, smooth_y, bcg_types=['empty'], bcg_channels=['C2'], refine_mask = False, binning=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254e0b8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
