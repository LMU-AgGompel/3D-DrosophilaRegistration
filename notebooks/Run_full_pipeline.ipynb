{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a07cb409-d49a-4524-b01d-9c0f365c4cc2",
   "metadata": {},
   "source": [
    "# Registration of confocal images of Drosophila abdomens \n",
    "\n",
    "This notebook runs the entire pipeline to register the confocal images of fly abdomens.\n",
    "The analysis is divided in few steps. \n",
    "Each step uses functions saved in files in the src folder and its subfolders. \n",
    "\n",
    "The results of each step of the analysis are saved in a series of numbered subfolders in the data folder.\n",
    "\n",
    "The raw data should be saved in the 01_raw subfolder as separate .tif files for each channel with a prefix that identifies the channel (like C1-filename.tif).  It should also contain an excel file with the columns \"image file name\", \"construct\" and \"quality\". These contain the name of each image stack, a label identifying which construct or genotype it is, and a label characterizing the quality of the raw data for filtering the results at a later point in the analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21102829-4228-4f22-b824-ac2a914c1066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "root_dir = os.path.join(os.getcwd(), '..')\n",
    "sys.path.append(root_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef71114d",
   "metadata": {},
   "source": [
    "## 1. Automated segmentation of the abdomens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f769d103-75a1-46c2-a1f4-063949295d83",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing of raw images in progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 9/9 [03:43<00:00, 24.80s/it]\n"
     ]
    }
   ],
   "source": [
    "# Importing the preprocessing function from the preprocess.py file:\n",
    "\n",
    "from src.preprocess import preprocess_and_segment_images\n",
    "\n",
    "raw_data_folder = \"../../data_2/01_raw\"\n",
    "destination_folder = \"../../data_2/02_preprocessed\"\n",
    "\n",
    "#downscaling of confocal stacks along z,x,y to make the resolution isotropic:\n",
    "downscaling = (1, 2.5, 2.5) \n",
    "\n",
    "# bit depth of raw images (depending on detector settings may be 8, 12 or 16)\n",
    "bit_depth = 12\n",
    "\n",
    "# name of the excel file containing the list of images to be used in the analysis. \n",
    "db_name = 'DatasetInformation.xlsx'\n",
    "\n",
    "preprocess_and_segment_images(raw_data_folder, destination_folder, downscaling, bit_depth, only_on_new_files = True, database_filename = db_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5d8776",
   "metadata": {},
   "source": [
    "## 2. Manual registration of the segmented 3D images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cde195c7-32dd-4180-b4f3-32440c376dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registration of 3D stacks in progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 9/9 [04:04<00:00, 27.12s/it]\n"
     ]
    }
   ],
   "source": [
    "# Importing the registration function from the registration.py file:\n",
    "\n",
    "from src.registration import registration_of_abdomens_3D\n",
    "\n",
    "\"\"\"\n",
    "# USER INPUT IS REQUIRED, two windows with a 3D rendering of the detected fly abdomen\n",
    "will pop-up for each image in the dataset. \n",
    "The first window shows the abdomen to register, the second one shows the reference abdomen.\n",
    "\n",
    "For each couple of images:\n",
    "1)  Please pick at least three correspondences using [shift + left click]\n",
    "    Press [shift + right click] to undo point picking)\n",
    "2)  After picking points, press 'Q' to close the window\n",
    "3)  Repeat points 1 and 2 for the reference image in the second window.\n",
    "4)  The next window will show the result of the registration, press 'Q' to close the window.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "read_folder = \"../../data_2/02_preprocessed\"\n",
    "destination_folder = \"../../data_2/03_registered\"\n",
    "\n",
    "reference_fly_filename = \"../../data_2/References_and_masks/C1_Reference_iso.tif\"\n",
    "abdomen_mask_file = \"../../data_2/References_and_masks/Reference_abdomen_mask_iso.tif\"\n",
    "\n",
    "df_name = \"DatasetInformation.xlsx\"\n",
    "\n",
    "preprocessed_df = pd.read_excel(os.path.join(read_folder,df_name))\n",
    "registration_of_abdomens_3D(preprocessed_df, read_folder, reference_fly_filename, abdomen_mask_file, destination_folder, only_on_new_files = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b256590d",
   "metadata": {},
   "source": [
    "## 3. Automated 2D projection of registered 3D images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79ccfee3-8e27-4a57-871e-d820aa423d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "Projection of registered 3D stacks to 2D images in progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 9/9 [02:19<00:00, 15.53s/it]\n"
     ]
    }
   ],
   "source": [
    "from src.projection import projections_of_abdomens\n",
    "\n",
    "read_folder = \"../../data_2/03_registered\"\n",
    "destination_folder = \"../../data_2/04_projected\"\n",
    "landmark_folder = \"../../data_2/05_landmarks/data\"\n",
    "abdomen_mask_file = \"../../data_2/References_and_masks/Reference_abdomen_mask_iso_thick.tif\"\n",
    "abdomen_shape_reference_file = \"../../data_2/References_and_masks/Reference_abdomen_mask_iso.tif\"\n",
    "\n",
    "df_name = \"DatasetInformation.xlsx\"\n",
    "df = pd.read_excel(os.path.join(read_folder,df_name))\n",
    "projections_of_abdomens(df, read_folder, destination_folder, landmark_folder, abdomen_mask_file, abdomen_shape_reference_file, crop_x=300, crop_y = 320)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5495686",
   "metadata": {},
   "source": [
    "##  4. Annotation and warping of the 2D projected images\n",
    "\n",
    "After the projection from 3D to 2D, images are already roughly aligned. However, the alignment up to this point was only performed by applying a global rescaling and rigid rotations/translations of the original stacks.\n",
    "\n",
    "To fine tune the registration we need to perform an elastic registration of the final images. We can do this using a separate software for 2D image annotation and registration.\n",
    "\n",
    "Run the image annotation software, open the annotation project, add the new images found in the folder 05_landmarks/data to the project. Annotate the new images and run the registration, save the results in the folder 06_warped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b442c82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import image_registration\n",
    "\n",
    "image_registration.gui.start(main_window_size = (1000, 1000), graph_canvas_width = 600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50b2e2f",
   "metadata": {},
   "source": [
    "## 5. Final touch: smoothing and masking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cebb4d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing of registered raw images in progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 123/123 [00:01<00:00, 102.25it/s]\n"
     ]
    }
   ],
   "source": [
    "from src.masking_smoothing import preprocess_registered_images\n",
    "\n",
    "destination_folder = \"../../data_2/07_masked_and_smooth\"\n",
    "read_folder = \"../../data_2/06_warped\"\n",
    "mask = '../../data_2/References_and_masks/mask.tif'\n",
    "database_registered_images = \"../../data_2/06_warped/dataframe_info.csv\"\n",
    "database_info = \"../../data_2/04_projected/DatasetInformation.xlsx\"\n",
    "\n",
    "preprocess_registered_images(read_folder, destination_folder, database_registered_images, database_info, mask_filename = mask, smooth_x=1, smooth_y = 5, binning=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022629ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
