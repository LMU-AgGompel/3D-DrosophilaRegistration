{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a07cb409-d49a-4524-b01d-9c0f365c4cc2",
   "metadata": {},
   "source": [
    "# Registration of confocal images of Drosophila abdomens \n",
    "\n",
    "This notebook runs the entire pipeline to register the confocal images of fly abdomens.\n",
    "The analysis is divided in few steps. Most of the code to perform each step is packed into python functions saved in files in the src folder and its subfolders. \n",
    "\n",
    "The results of each step of the analysis are saved in a series of ordered subfolders of the data folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21102829-4228-4f22-b824-ac2a914c1066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "root_dir = os.path.join(os.getcwd(), '..')\n",
    "sys.path.append(root_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef71114d",
   "metadata": {},
   "source": [
    "## 1. Automated segmentation of the abdomens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f769d103-75a1-46c2-a1f4-063949295d83",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing of raw images in progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 6/6 [06:52<00:00, 68.71s/it]\n"
     ]
    }
   ],
   "source": [
    "# Importing the preprocessing function from the preprocess.py file:\n",
    "\n",
    "from src.preprocess import preprocess_and_segment_images\n",
    "\n",
    "raw_data_folder = \"../../data_2/01_raw\"\n",
    "destination_folder = \"../../data_2/02_preprocessed\"\n",
    "\n",
    "#downscaling of confocal stacks along z,x,y:\n",
    "downscaling = (1, 2.5, 2.5)\n",
    "\n",
    "# bit depth of raw images (depending on detector settings may be 8, 12 or 16)\n",
    "bit_depth = 12\n",
    "\n",
    "# name of the excel file containing the list of images to be used in the analysis. \n",
    "db_name = 'DatasetInformation.xlsx'\n",
    "\n",
    "preprocess_and_segment_images(raw_data_folder, destination_folder, downscaling, bit_depth, only_on_new_files = True, database_filename = db_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5d8776",
   "metadata": {},
   "source": [
    "## 2. Manual registration of the segmented 3D images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cde195c7-32dd-4180-b4f3-32440c376dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registration of 3D stacks in progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 6/6 [08:36<00:00, 86.00s/it]\n"
     ]
    }
   ],
   "source": [
    "# Importing the registration function from the registration.py file:\n",
    "\n",
    "from src.registration import registration_of_abdomens_3D\n",
    "\n",
    "\"\"\"\n",
    "# USER INPUT IS REQUIRED, a series of 3D viewer windows will pop-up for each image in the dataset.\n",
    "\n",
    "For each couple of images:\n",
    "1)  Please pick at least three correspondences using [shift + left click]\n",
    "    Press [shift + right click] to undo point picking)\n",
    "2)  After picking points, press 'Q' to close the window\n",
    "3)  Repeat points 1 and 2 for the second image.\n",
    "4)  The next window will show the result of the registration, press 'Q' to close the window\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "read_folder = \"../../data_2/02_preprocessed\"\n",
    "destination_folder = \"../../data_2/03_registered\"\n",
    "\n",
    "reference_fly_filename = \"../../data_2/References_and_masks/C1_Reference_iso.tif\"\n",
    "abdomen_mask_file = \"../../data_2/References_and_masks/Reference_abdomen_mask_iso.tif\"\n",
    "\n",
    "df_name = \"DatasetInformation.xlsx\"\n",
    "\n",
    "preprocessed_df = pd.read_excel(os.path.join(read_folder,df_name))\n",
    "registration_of_abdomens_3D(preprocessed_df, read_folder, reference_fly_filename, abdomen_mask_file, destination_folder, only_on_new_files = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b256590d",
   "metadata": {},
   "source": [
    "## 3. Automated 2D projection of registered 3D images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ccfee3-8e27-4a57-871e-d820aa423d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Projection of registered 3D stacks to 2D images in progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████████████████████████████               | 4/6 [00:38<00:20, 10.17s/it]"
     ]
    }
   ],
   "source": [
    "from src.projection import projections_of_abdomens\n",
    "\n",
    "read_folder = \"../../data_2/03_registered\"\n",
    "destination_folder = \"../../data_2/04_projected\"\n",
    "landmark_folder = \"../../data_2/05_landmarks/data\"\n",
    "abdomen_mask_file = \"../../data_2/References_and_masks/Reference_abdomen_mask_iso_thick.tif\"\n",
    "abdomen_shape_reference_file = \"../../data_2/References_and_masks/Reference_abdomen_mask_iso.tif\"\n",
    "\n",
    "df_name = \"DatasetInformation.xlsx\"\n",
    "df = pd.read_excel(os.path.join(read_folder,df_name))\n",
    "projections_of_abdomens(df, read_folder, destination_folder, landmark_folder, abdomen_mask_file, abdomen_shape_reference_file, crop_x=300, crop_y = 320)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5495686",
   "metadata": {},
   "source": [
    "##  4. Annotation and warping of the 2D projected images\n",
    "\n",
    "After the projection from 3D to 2D, images are already roughly aligned. However, the alignment up to this point was only performed by applying a global rescaling and rigid rotations/translations of the original stacks.\n",
    "\n",
    "To fine tune the registration we need to manually place landmarks on the 2D projected images and apply an elastic deformation of the images.\n",
    "\n",
    "Run the image annotation software, open the annotation project, add the new images found in the folder 05_landmarks/data to the project.\n",
    "\n",
    "Annotate the new images and run the registration, save the results in the folder 06_warped."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50b2e2f",
   "metadata": {},
   "source": [
    "## 5. Final touch: smoothing and masking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cebb4d65",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../data_2/06_warped/dataframe_info.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_42334/1518361367.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdatabase_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"../../data_2/04_projected/DatasetInformation.xlsx\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mpreprocess_registered_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mread_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestination_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatabase_registered_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatabase_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmoothing_sigma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinning\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/media/ceolin/Data/Lab Gompel/Projects/Fly_Abdomens/abdomens_registration/notebooks/../src/masking_smoothing.py\u001b[0m in \u001b[0;36mpreprocess_registered_images\u001b[0;34m(read_folder, destination_folder, database_registered, database_info, mask_filename, smoothing_sigma, bcg_construct, binning)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;31m# unify databases across folders:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0mraw_data_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_raw_images_database\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mread_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatabase_registered\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatabase_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;31m# clean the destination directory:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/ceolin/Data/Lab Gompel/Projects/Fly_Abdomens/abdomens_registration/notebooks/../src/masking_smoothing.py\u001b[0m in \u001b[0;36mcreate_raw_images_database\u001b[0;34m(folder, database_registered_path, database_info_path)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_raw_images_database\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatabase_registered_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatabase_info_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m     \u001b[0mraw_data_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatabase_registered_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m     \u001b[0minfo_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatabase_info_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0minfo_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfo_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"image file name\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"construct\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/abdomens/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/abdomens/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/abdomens/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/abdomens/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1048\u001b[0m             )\n\u001b[1;32m   1049\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/abdomens/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1867\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1869\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/abdomens/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m         \"\"\"\n\u001b[0;32m-> 1362\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/abdomens/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    645\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"replace\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 647\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    648\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../data_2/06_warped/dataframe_info.csv'"
     ]
    }
   ],
   "source": [
    "from src.masking_smoothing import preprocess_registered_images\n",
    "\n",
    "destination_folder = \"../../data_2/07_masked_and_smooth\"\n",
    "read_folder = \"../../data_2/06_warped\"\n",
    "mask = '../../data_2/References_and_masks/2D_mask_abdomen_vertical-1.tif'\n",
    "database_registered_images = \"../../data_2/06_warped/dataframe_info.csv\"\n",
    "database_info = \"../../data_2/04_projected/DatasetInformation.xlsx\"\n",
    "\n",
    "preprocess_registered_images(read_folder, destination_folder, database_registered_images, database_info, mask_filename = mask, smoothing_sigma=4, binning=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022629ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
