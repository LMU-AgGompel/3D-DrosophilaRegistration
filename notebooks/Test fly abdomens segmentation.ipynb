{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3c0da04",
   "metadata": {},
   "source": [
    "# Test Fly Abdomens Segmentation\n",
    "\n",
    "This notebook is used to test separately each step used in the detection and segmentation of the surface of the abdomen in an image stack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8b4d220-5903-49e8-8704-d26569a4263c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "# import packages \n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import copy\n",
    "import napari\n",
    "import time\n",
    "import os\n",
    "from skimage import morphology\n",
    "from skimage.measure import label, regionprops, block_reduce\n",
    "from scipy import stats, ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "root_dir = os.path.join(os.getcwd(), '..')\n",
    "sys.path.append(root_dir)\n",
    "\n",
    "from src.preprocess import segmentation_with_optimized_thresh, image_padding\n",
    "from src.registration import image_to_pcd, pcd_to_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "661869ed-6f47-49af-ab59-a0e1790396a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the image, only fluorescence channel is required:\n",
    "# reference_fly_filename = \"../../data_2/01_raw/C1-D3_En_male_03_20220805.tif\"\n",
    "reference_fly_filename = \"../../data_2/01_raw/C1-D0_En_pn_male_06_20220708.tif\"\n",
    "\n",
    "image = io.imread(reference_fly_filename)\n",
    "\n",
    "# Downscaling:\n",
    "downscaling =  (1,2.5,2.5)\n",
    "new_image_shape = [int(image.shape[i]/downscaling[i]) for i in range(3)]\n",
    "image_downscaled = transform.resize(image, new_image_shape, preserve_range = True, anti_aliasing=True)\n",
    "#viewer = napari.view_image(image_downscaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c088fcb",
   "metadata": {},
   "source": [
    "### Thresholding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "952aa3e4-e2db-4b1a-ad04-9f695c0e7652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing of the image took:  0.2934141159057617 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2023-04-20 18:17:51,900 - acceleratesupport - No OpenGL_accelerate module loaded: No module named 'OpenGL_accelerate'\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "# Segment:\n",
    "Thresholded_Image = segmentation_with_optimized_thresh(image_downscaled, fraction_range = [0.05, 0.06])\n",
    "t1 = time.time()\n",
    "viewer = napari.view_image(Thresholded_Image)\n",
    "# print running time:\n",
    "\n",
    "print(\"Preprocessing of the image took: \", t1-t0, \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c89736",
   "metadata": {},
   "source": [
    "## Clean up the segmented volume with morphological transformations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a983d3d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing of the image took:  8.856957912445068 seconds\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "# Padding:\n",
    "Thresholded_Image  = image_padding(Thresholded_Image)\n",
    "Image_padded = image_padding(image_downscaled)\n",
    "\n",
    "# Clean up the segmentation with morphological transformations:\n",
    "closing_r1 = 4\n",
    "\n",
    "# Dilate and erode again to fill small holes:\n",
    "filled = morphology.closing(Thresholded_Image, morphology.ball(closing_r1))\n",
    "\n",
    "label_image = label(filled)\n",
    "rp = regionprops(label_image)\n",
    "size = max([i.area for i in rp])\n",
    "\n",
    "biggest_objects = morphology.remove_small_objects(label_image, min_size=size/100)>0\n",
    "Thresholded_Image = biggest_objects\n",
    "\n",
    "# make the segmented volume thin by looking for the maxima in the signal\n",
    "from scipy.signal import find_peaks\n",
    "def local_maxima_z(image, dist):\n",
    "    # maxima along z\n",
    "    result = np.zeros(image.shape)\n",
    "    \n",
    "    for i in range(image.shape[1]):\n",
    "        for j in range(image.shape[2]):\n",
    "            peaks, _ = find_peaks(image[:,i,j], distance = dist)\n",
    "            for p in peaks:\n",
    "                result[p,i,j] = 1\n",
    "    \n",
    "    return result\n",
    "\n",
    "def local_maxima_x(image, dist):\n",
    "    # maxima along x\n",
    "    result = np.zeros(image.shape)\n",
    "    \n",
    "    for i in range(image.shape[0]):\n",
    "        for j in range(image.shape[2]):\n",
    "            peaks, _ = find_peaks(image[i,:,j], distance = dist)\n",
    "            for p in peaks:\n",
    "                result[i,p,j] = 1\n",
    "    \n",
    "    return result\n",
    "\n",
    "def local_maxima_y(image, dist):\n",
    "    # maxima along y\n",
    "    result = np.zeros(image.shape)\n",
    "    \n",
    "    for i in range(image.shape[0]):\n",
    "        for j in range(image.shape[1]):\n",
    "            peaks, _ = find_peaks(image[i,j,:], distance = dist)\n",
    "            for p in peaks:\n",
    "                result[i,j,p] = 1\n",
    "    \n",
    "    return result\n",
    "\n",
    "Maxima_z = local_maxima_z(Thresholded_Image*Image_padded, 100)\n",
    "#Maxima_y = local_maxima_y(Thresholded_Image*Image_padded, 50)\n",
    "#Maxima_x = local_maxima_x(Thresholded_Image*Image_padded, 50)\n",
    "Thresholded_Image = Maxima_z#(Maxima_z+Maxima_y+Maxima_x) > 0\n",
    "\n",
    "t1 = time.time()\n",
    "viewer = napari.view_image(Thresholded_Image)\n",
    "# print running time:\n",
    "\n",
    "print(\"Preprocessing of the image took: \", t1-t0, \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6189a5c",
   "metadata": {},
   "source": [
    "## Transform the segmented volume in a point cloud object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70a2dc91-45b8-436c-a13e-4c8893553cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_draw(pcd):\n",
    "    # The following code achieves the same effect as:\n",
    "    # o3d.visualization.draw_geometries([pcd])\n",
    "    vis = o3d.visualization.Visualizer()\n",
    "    vis.create_window()\n",
    "    opt = vis.get_render_option()\n",
    "    opt.background_color = np.asarray([0, 0, 0])\n",
    "    vis.add_geometry(pcd)\n",
    "    vis.run()\n",
    "    vis.destroy_window()\n",
    "    \n",
    "def custom_draw_w_mesh(pcd, mesh):\n",
    "    # The following code achieves the same effect as:\n",
    "    # o3d.visualization.draw_geometries([pcd])\n",
    "    vis = o3d.visualization.Visualizer()\n",
    "    vis.create_window()\n",
    "    opt = vis.get_render_option()\n",
    "    opt.background_color = np.asarray([0, 0, 0])\n",
    "    vis.add_geometry(pcd)\n",
    "    vis.add_geometry(mesh)\n",
    "    vis.run()\n",
    "    vis.destroy_window()\n",
    "    \n",
    "def draw_pcd(pcd):\n",
    "    pcd_temp = copy.deepcopy(pcd)\n",
    "    pcd_temp.paint_uniform_color([1, 0.706, 0])\n",
    "    o3d.visualization.draw_geometries([pcd_temp])\n",
    "    \n",
    "\n",
    "def skeletonize_on_slices(image_3d):\n",
    "    \n",
    "    result = np.zeros(image_3d.shape)\n",
    "    \n",
    "    for i in range(image_3d.shape[1]):\n",
    "        image = image_3d[:,i,:]\n",
    "        skeleton = morphology.skeletonize(image)\n",
    "        result[:,i,:] = skeleton\n",
    "\n",
    "    return result\n",
    "    \n",
    "\n",
    "# Create a pcd from the thresholded image\n",
    "pcd, pcd_values = image_to_pcd(Thresholded_Image)\n",
    "custom_draw(pcd)\n",
    "\n",
    "# Remove outliers from the pcd, based on n_neighbrours within a radius:\n",
    "uni_down_pcd = pcd.uniform_down_sample(every_k_points=3)\n",
    "custom_draw(uni_down_pcd)\n",
    "cleaned_pcd = uni_down_pcd\n",
    "#cleaned_pcd, ind = uni_down_pcd.remove_radius_outlier(nb_points=4, radius=4)\n",
    "#cleaned_pcd, ind = cleaned_pcd.remove_radius_outlier(nb_points=4, radius=4)\n",
    "#cleaned_pcd, ind = cleaned_pcd.remove_radius_outlier(nb_points=4, radius=3)\n",
    "\n",
    "# downsampling\n",
    "cleaned_pcd = cleaned_pcd.voxel_down_sample(voxel_size=5)\n",
    "custom_draw(cleaned_pcd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22255f36",
   "metadata": {},
   "source": [
    "## Fit a mesh through the point cloud to close potential holes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11307991-4b14-40a6-876b-f47166687194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mesh that fits through the cleaned points to fill potential holes:\n",
    "cleaned_pcd.estimate_normals()\n",
    "cleaned_pcd.orient_normals_consistent_tangent_plane(k=30)\n",
    "\n",
    "#flip normals:\n",
    "normals = -np.asarray(cleaned_pcd.normals)\n",
    "cleaned_pcd.normals = o3d.utility.Vector3dVector(normals)\n",
    "\n",
    "#visualize normals:\n",
    "#o3d.visualization.draw_geometries([cleaned_pcd], point_show_normal=True)\n",
    "\n",
    "radii = [30]\n",
    "ball_mesh = o3d.geometry.TriangleMesh.create_from_point_cloud_ball_pivoting(cleaned_pcd, o3d.utility.DoubleVector(radii))\n",
    "bbox = cleaned_pcd.get_axis_aligned_bounding_box()\n",
    "ball_mesh_crop = ball_mesh.crop(bbox)\n",
    "ball_mesh_crop.paint_uniform_color([1,1,1])\n",
    "\n",
    "custom_draw_w_mesh(cleaned_pcd, ball_mesh_crop)\n",
    "resampled_pcd = ball_mesh_crop.sample_points_uniformly(number_of_points = 50000)\n",
    "custom_draw(resampled_pcd)\n",
    "\n",
    "final_pcd = o3d.geometry.PointCloud()\n",
    "final_pcd.points = o3d.utility.Vector3dVector( np.concatenate((pcd.points, resampled_pcd.points), axis=0) )\n",
    "\n",
    "custom_draw(final_pcd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a72eaf7",
   "metadata": {},
   "source": [
    "## Create a mask from the mesh and apply it to the original image stack:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "edd043b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pcd_values = np.ones(np.asarray(final_pcd.points).shape[0])\n",
    "final_image = pcd_to_image(final_pcd, final_pcd_values, Thresholded_Image.shape)\n",
    "final_image = morphology.dilation(final_image, morphology.ball(8))\n",
    "viewer = napari.view_image(final_image*Image_padded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806c853c",
   "metadata": {},
   "source": [
    "## Save the masked image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5dc1b1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save it as reference\n",
    "from tifffile import imsave\n",
    "imsave(\"../../data_2/References_and_masks/C1_Reference_iso.tiff\", (final_image*Image_padded).astype(np.uint16))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
